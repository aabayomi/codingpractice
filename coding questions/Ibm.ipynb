{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interview Questions\n",
    "What about your background qualifies you for this position?  \n",
    "Answer Question\n",
    "what technology have you been learning on your own? what are the pros and cons of this technology?  \n",
    "Answer Question\n",
    "Implement Max Pooling Algorithm\n",
    "In Neural Networks used for Visual Recognition some layers perform a Max Pooling operation on an image represented as an NxM matrix of intensities (most often it is\n",
    " squared but we do not make this assumption in this task). Max Pooling consists of the following: given a window of size KxL, “slide” the window through the array\n",
    " without overlapping and return the maximum values for each window.\n",
    "\n",
    "It’s best explained with an example:\n",
    "\n",
    "Given a 4x4 matrix\n",
    "\n",
    "1 1 2 4\n",
    "5 6 7 8\n",
    "3 2 1 0\n",
    "1 2 3 4\n",
    "and a square window of size 2x2, the subregions are:\n",
    "\n",
    "1 1 | 2 4\n",
    "5 6 | 7 8\n",
    "--------\n",
    "3 2 | 1 0\n",
    "1 2 | 3 4\n",
    "The corresponding Max Pooled values for each subregions are:\n",
    "\n",
    "6 8\n",
    "3 4\n",
    "A square window of size 1x1 will return the original matrix.\n",
    "\n",
    "For this task we will make the following assumptions:\n",
    "\n",
    "Matrices will only contain integers in the range (-1000, 1000)\n",
    "Matrices are always 2 dimensional (but not always square) and non-empty\n",
    "We will always use a square window (so we’ll provide only 1 size)\n",
    "The output should be the sum of Max Pooled values (e.g., 21 for the example above)\n",
    "If the window cannot fit into the matrix without overlapping, the output should be the string “NONE”\n",
    "\n",
    "Input:\n",
    "The rows of the matrix each on a separate line, followed by a blank line, and then a single number for the Max Pooling window size.\n",
    "\n",
    "Output:\n",
    "Print to standard output the sum of the Max Pooled values, or the string “NONE” if assumptions are not fulfilled.\n",
    "\n",
    "Test 1\n",
    "Input\n",
    "20 200\n",
    "-13 134\n",
    "120 32\n",
    "-120 124\n",
    "\n",
    "Expected Output:\n",
    "NONE\n",
    "\n",
    "Test 2\n",
    "Test Input\n",
    "20 200\n",
    "-13 134\n",
    "120 32\n",
    "-120 12\n",
    "\n",
    "Expected Output\n",
    "Output:\n",
    "320\n",
    "\n",
    "Test 3\n",
    "Test Input:\n",
    "1 1 2 4\n",
    "5 6 7 8\n",
    "3 2 1 0\n",
    "1 2 3 4\n",
    "\n",
    "Expected Output\n",
    "21  \n",
    "Answer Question\n",
    "Show Less\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming Challenge Description:\n",
    "Crawl an HTML page to extract file names containing certain patterns from hyperlinks\n",
    "Given a one line HTML \"page\", find all hyperlinks (e.g., URLs specified within <a href=http://sample.url/> and not as plain text) and return all the names of zip files that contain word\n",
    "\"data\" and come from www.example.com web site. The output should be a comma-separated list without spaces. If no such file was detected, print empty line (e.g., “”).\n",
    "\n",
    "Example:\n",
    "\n",
    "Input:\n",
    "<a href=http://www.example.com/global_data.zip > some text </a> Some other text <a href=http://www.example.com/local_data.zip> some more text </a>\n",
    "\n",
    "Output:\n",
    "global_data.zip,local_data.zip\n",
    "\n",
    "Input:\n",
    "Your program should read lines of text from standard input. Each line may or may not contain one or more target files.\n",
    "\n",
    "Output:\n",
    "Print to standard output a single line containing a comma-separated list of such file names without spaces. If no such file was detected, print empty line (e.g., “”).\n",
    "\n",
    "Test 1\n",
    "Test Input\n",
    " &nbsp;<a href=\"http://www.example.com/files/world_data1.zip\"><b>World Data Part 1</b></a> <br/> <a href=\"http://www.example.com/files/world_data2.zip\"><b>World Data Part 2</b></a>\n",
    "Expected Output\n",
    "world_data1.zip,world_data2.zip\n",
    "\n",
    "Test 2\n",
    "Test Input\n",
    "<td background=\"./files/buttonbg.gif\"><a href=\"http://www.example.com/global_data.zip\" onmouseover=\"setOverImg(&#39;11&#39;,&#39;&#39;);\n",
    "Expected Output:\n",
    "global_data.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Hello World\\nThis is a link'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# htmltxt = \"<p>Hello World</p>\"\n",
    "# soup = BeautifulSoup(htmltxt, 'lxml')\n",
    "\n",
    "# soup.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Hello World\\nThis is a link'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytxt = \"\"\"\n",
    "<h1>Hello World</h1>\n",
    "<p>This is a <a href=\"http://example.com\">link</a></p>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(mytxt, 'lxml')   # text attribute will return a string stripped of any HTML tags and metadata.\n",
    "soup.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://example.com\">link</a>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytxt = \"\"\"\n",
    "<h1>Hello World</h1>\n",
    "<p>This is a <a href=\"http://example.com\">link</a></p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(mytxt, 'lxml')\n",
    "soup.find('a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'link'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "mytxt = \"\"\"\n",
    "<h1>Hello World</h1>\n",
    "<p>This is a <a href=\"http://example.com\">link</a></p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(mytxt, 'lxml')\n",
    "mylink = soup.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'http://example.com'}\n",
      "http://example.com\n"
     ]
    }
   ],
   "source": [
    "type(mylink.attrs)\n",
    "# dict\n",
    "print mylink.attrs\n",
    "# {'href': 'http://example.com'}\n",
    "print mylink.attrs['href']\n",
    "# 'http://example.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moretxt = \"\"\"\n",
    "<p>Visit the <a href='http://www.nytimes.com'>New York Times</a></p>\n",
    "<p>Visit the <a href='http://www.wsj.com'>Wall Street Journal</a></p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(moretxt, 'lxml')\n",
    "tags = soup.find_all('a')\n",
    "type(tags)\n",
    "# bs4.element.ResultSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'http://www.nytimes.com'}\n",
      "(u'New York Times', 'http://www.nytimes.com')\n",
      "(u'Wall Street Journal', 'http://www.wsj.com')\n"
     ]
    }
   ],
   "source": [
    "len(tags)\n",
    "# 2\n",
    "tags[0].text\n",
    "# New York Times\n",
    "tags[0].attrs['href']\n",
    "print tags[0].attrs\n",
    "'http://www.nytimes.com'\n",
    "for t in tags:\n",
    "    print(t.text, t.attrs['href'])\n",
    "# New York Times http://www.nytimes.com\n",
    "# Wall Street Journal http://www.wsj.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"http://www.a.com\">Awesome</a>, <a href=\"http://www.b.com\">Really Awesome</a>]\n"
     ]
    }
   ],
   "source": [
    "evenmoretxt = \"\"\"\n",
    "<h1><a href=\"http://www.a.com\">Awesome</a></h1>\n",
    "<h1><a href=\"http://www.b.com\">Really Awesome</a></h1>\n",
    "\n",
    "<div><a href=\"http://na.com\">Ignore me</a></div>\n",
    "<div><a href=\"http://127.0.0.1\">Ignore me again</a></div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(evenmoretxt, 'lxml')\n",
    "\n",
    "heds = soup.find_all('h1')\n",
    "\n",
    "links = []\n",
    "for h in heds:\n",
    "    a = h.find('a')\n",
    "    links.append(a)\n",
    "print links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(sInput):\n",
    "    \n",
    "    soup = BeautifulSoup(sInput, 'lxml')\n",
    "    downloads = soup.find_all('a')\n",
    "\n",
    "    b = []\n",
    "    for d in downloads:\n",
    "        b.append(d.attrs['href'])\n",
    "#     print b\n",
    "\n",
    "    new = []\n",
    "    for items in b:\n",
    "        new.append(items[7:])\n",
    "#     print new \n",
    "\n",
    "    down = []\n",
    "\n",
    "    for link in new:\n",
    "        l=link.split(\"/\")\n",
    "        down.append(l[-1])\n",
    "        \n",
    "    return down "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['global_data.zip', 'local_data.zip']\n",
      "['world_data1.zip', 'world_data2.zip']\n",
      "['global_data.zip']\n"
     ]
    }
   ],
   "source": [
    "sInput1 = \"\"\"<a href=http://www.example.com/global_data.zip > some text \n",
    "</a> Some other text <a href=http://www.example.com/local_data.zip> some more text </a>\"\"\"\n",
    "\n",
    "sInput2 = \"\"\"&nbsp;<a href=\"http://www.example.com/files/world_data1.zip\"><b>World Data Part 1</b></a> <br/> \n",
    "<a href=\"http://www.example.com/files/world_data2.zip\"><b>World Data Part 2</b></a>\n",
    "\"\"\"\n",
    "sInput3 = \"\"\"<td background=\"./files/buttonbg.gif\">\n",
    "<a href=\"http://www.example.com/global_data.zip\" onmouseover=\"setOverImg(&#39;11&#39;,&#39;&#39;);\n",
    "\"\"\"\n",
    "\n",
    "print parser(sInput1)\n",
    "print parser(sInput2)\n",
    "print parser(sInput3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming Challenge Description:\n",
    "Find the most similar pair using cosine\n",
    "\n",
    "Given a sequence of passages, find the most similar pair using the cosine similarity measure. If there are ties (more than one pair have the same similarity score), return the one with the leftmost passage. If there’s only 1 passage in a sequence, return it. Do not return similarity of a passage with itself.\n",
    "\n",
    "How to represent a passage in the vocabulary space:\n",
    "\n",
    "The vocabulary space includes all words encountered in any of the passages ignoring their case. Any non-alphanumeric characters are also ignored, spaces trimmed.\n",
    "A passage is represented as a vector of its word frequencies in a vocabulary space.\n",
    "For example, if we have a set of passages “I like ice cream”, “My sister likes ice cream too”, the vocabulary space would include “coordinates”: [I, like, likes, ice, cream, my, sister, too]. Note that (1) we do not ask to bring different wordforms o a common lexeme (as “like” and “likes”) so they are considered different words; (2) we consider complex words as separate lexemes (e.g., “ice” and “cream” from “ice cream”). Then the first passage will be represented as [1, 1, 0, 1, 1, 0, 0, 0] and the second passage will be represented as [0, 0, 1, 1, 1, 1, 1, 1].\n",
    "The cosine measure (click Attachment above for equation image):\n",
    "\n",
    "The cosine between 2 vectors A and B equals the scalar product of the vectors divided by the product of vector length.\n",
    "For example, in a 3 dimensional space for vector A=(1, 2, 2) and vector B=(1, 0, 0), the cosine measure is (1*1 + 2*0 + 2*0) / ((1^2 + 2^2 + 2^2)^(1/2) * (1^2 + 0^2 + 0^2)^(1/2)) = 1/3\n",
    "The larger the cosine (reminder: cosine max value is 1), the more similar passages are.\n",
    "\n",
    "Input:\n",
    "A single line comprising the passages (strings) to be processed, delimited by | characters. The | characters are not considered part of any passage.\n",
    "\n",
    "Output:\n",
    "The comma-separated (no space) numbers of the most similar passages. For a single passage return 0.\n",
    "\n",
    "Test 1\n",
    "Test Input:\n",
    "IBM cognitive computing|IBM \"cognitive\" computing is a revolution| ibm cognitive computing|'IBM Cognitive Computing' is a revolution?\n",
    "Expected Output\n",
    "0,2\n",
    "Test 2\n",
    "Test Input\n",
    "The cat is on the mat | The cat likes the mat | The dog is on the mat | The dog chews the mat\n",
    "Expected Output\n",
    "0,2  \n",
    "Answer Question\n",
    "Show Less"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
